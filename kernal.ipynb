{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Importing the Keras libraries and packages\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Convolution2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dense\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.layers import Dropout\n",
    "from keras.callbacks import EarlyStopping\n",
    "import random\n",
    "from imutils import paths\n",
    "import os\n",
    "from keras.utils import to_categorical\n",
    "from cnnmodel.similarvggnet import SmallerVGGNet\n",
    "from keras import optimizers\n",
    "from keras.preprocessing.image import img_to_array\n",
    "import numpy as np\n",
    "import shutil\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import cv2\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] loading images...\n"
     ]
    }
   ],
   "source": [
    "print(\"[INFO] loading images...\")\n",
    "imagePaths = sorted(list(paths.list_images('Dataset')))\n",
    "random.seed(42)\n",
    "random.shuffle(imagePaths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 500\n",
    "INIT_LR = 1e-4\n",
    "BS = 256\n",
    "w=200#you can change this in a multiple of 2\n",
    "h=200\n",
    "\n",
    "# initialize the data and labels\n",
    "data = []\n",
    "labels = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "for imagePath in imagePaths:\n",
    "    image = cv2.imread(imagePath)\n",
    "    image = cv2.resize(image, (w,h))#resize image maintaining aspect ratio\n",
    "#     b, g, r = cv2.split(image)\n",
    "#     cv2.imshow('imgage',g)\n",
    "#     cv2.waitkey(0)\n",
    "#     key = cv2.waitKey()\n",
    "#     cv2.destroyAllWindows()\n",
    "    g = image\n",
    "    image = img_to_array(g)\n",
    "    data.append(image)\n",
    "    label = imagePath.split(os.path.sep)[-1].split('_')[0]\n",
    "    if label == 'Angry':\n",
    "        label = 0\n",
    "    elif label == 'Disgusted':\n",
    "        label = 1\n",
    "    elif label == 'Afraid':\n",
    "        label = 2\n",
    "    elif label == 'Sad':\n",
    "        label = 3\n",
    "    elif label == 'Happy':\n",
    "        label = 4\n",
    "    elif label == 'Neutral':\n",
    "        label = 5\n",
    "    else:\n",
    "        label = 6\n",
    "    \n",
    "    labels.append(label)\n",
    "\n",
    "# scale the raw pixel intensities to the range [0, 1]\n",
    "data = np.array(data, dtype=\"float\") / 255.0\n",
    "labels = np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "(trainX, testX, trainY, testY) = train_test_split(data, labels, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainY = to_categorical(trainY, num_classes=7)\n",
    "testY = to_categorical(testY, num_classes=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "aug = ImageDataGenerator(zca_whitening=True,fill_mode=\"nearest\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checking if a folder already exists. If not create a new one.\n",
    "if os.path.exists('AugmentedImages'):\n",
    "    shutil.rmtree('AugmentedImages')\n",
    "os.mkdir('AugmentedImages')\n",
    "\n",
    "#Saving and displaying augmented images\n",
    "for X_batch, y_batch in aug.flow(trainX, trainY, batch_size=len(trainX),save_to_dir='AugmentedImages',save_prefix='aug', save_format='png'):\n",
    "    # create a grid of 2x2 images\n",
    "    for i in range(0, 4):\n",
    "        plt.subplot(220 + 1 + i)\n",
    "        plt.imshow(X_batch[i])\n",
    "    # show the plot\n",
    "    plt.show()\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# train_datagen = ImageDataGenerator(rescale = 1./255,\n",
    "#                                    shear_range = 0.2,\n",
    "#                                    zoom_range = 0.2,\n",
    "#                                    horizontal_flip = True)\n",
    "\n",
    "# test_datagen = ImageDataGenerator(rescale = 1./255)\n",
    "\n",
    "# training_set = train_datagen.flow_from_directory('Dataset/training_set',\n",
    "#                                                  target_size = (64, 64),\n",
    "#                                                  batch_size = 32,\n",
    "#                                                  class_mode = 'binary')\n",
    "\n",
    "# test_set = test_datagen.flow_from_directory('Dataset/test_set',\n",
    "#                                             target_size = (64, 64),\n",
    "#                                             batch_size = 32,\n",
    "#                                             class_mode = 'binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for X_batch, y_batch in train_datagen.flow_from_directory('Dataset/training_set', batch_size=50, save_format='png'):\n",
    "#     # create a grid of 2x2 images\n",
    "#     for i in range(0, 4):\n",
    "#         plt.subplot(220 + 1 + i)\n",
    "#         plt.imshow(X_batch[i], cmap=plt.get_cmap('gray'))\n",
    "#     # show the plot\n",
    "#     plt.show()\n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_5 (Conv2D)            (None, 41, 63, 16)        448       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 20, 31, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 18, 29, 64)        9280      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 (None, 9, 14, 64)         0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 8064)              0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 64)                516160    \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 7)                 455       \n",
      "=================================================================\n",
      "Total params: 526,343\n",
      "Trainable params: 526,343\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tazer/anaconda3/envs/tf/lib/python3.7/site-packages/ipykernel_launcher.py:5: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(16, (3, 3), input_shape=(43, 65, 3..., activation=\"relu\")`\n",
      "  \"\"\"\n",
      "/home/tazer/anaconda3/envs/tf/lib/python3.7/site-packages/ipykernel_launcher.py:11: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (3, 3), activation=\"relu\")`\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "/home/tazer/anaconda3/envs/tf/lib/python3.7/site-packages/ipykernel_launcher.py:18: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=64)`\n",
      "/home/tazer/anaconda3/envs/tf/lib/python3.7/site-packages/ipykernel_launcher.py:20: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"softmax\", units=7)`\n"
     ]
    }
   ],
   "source": [
    "# Initialising the CNN\n",
    "classifier = Sequential()\n",
    "\n",
    "# Step 1 - Convolution\n",
    "classifier.add(Convolution2D(16, 3, 3, input_shape = (h, w, 3), activation = 'relu'))\n",
    "\n",
    "# Step 2 - Pooling\n",
    "classifier.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "\n",
    "# Adding a second convolutional layer\n",
    "classifier.add(Convolution2D(64, 3, 3, activation = 'relu'))\n",
    "classifier.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "\n",
    "# Step 3 - Flattening\n",
    "classifier.add(Flatten())\n",
    "\n",
    "# Step 4 - Full connection\n",
    "classifier.add(Dense(output_dim = 64, activation = 'relu'))\n",
    "# classifier.add(Dropout(0.2))\n",
    "classifier.add(Dense(output_dim = 7, activation = 'softmax'))\n",
    "\n",
    "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=2)\n",
    "\n",
    "# Compiling the CNN\n",
    "classifier.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "print(classifier.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "57/57 [==============================] - 4s 73ms/step - loss: 0.4114 - acc: 0.8571 - val_loss: 0.4094 - val_acc: 0.8571\n",
      "Epoch 2/500\n",
      "57/57 [==============================] - 4s 65ms/step - loss: 0.4072 - acc: 0.8571 - val_loss: 0.4035 - val_acc: 0.8571\n",
      "Epoch 3/500\n",
      "57/57 [==============================] - 4s 71ms/step - loss: 0.3973 - acc: 0.8572 - val_loss: 0.3838 - val_acc: 0.8571\n",
      "Epoch 4/500\n",
      "57/57 [==============================] - 5s 91ms/step - loss: 0.3705 - acc: 0.8584 - val_loss: 0.3571 - val_acc: 0.8632\n",
      "Epoch 5/500\n",
      "57/57 [==============================] - 5s 90ms/step - loss: 0.3512 - acc: 0.8645 - val_loss: 0.3532 - val_acc: 0.8637\n",
      "Epoch 6/500\n",
      "57/57 [==============================] - 5s 90ms/step - loss: 0.3296 - acc: 0.8711 - val_loss: 0.3421 - val_acc: 0.8660\n",
      "Epoch 7/500\n",
      "57/57 [==============================] - 5s 90ms/step - loss: 0.3221 - acc: 0.8708 - val_loss: 0.3342 - val_acc: 0.8683\n",
      "Epoch 8/500\n",
      "57/57 [==============================] - 6s 101ms/step - loss: 0.3063 - acc: 0.8774 - val_loss: 0.3312 - val_acc: 0.8707\n",
      "Epoch 9/500\n",
      "57/57 [==============================] - 5s 89ms/step - loss: 0.2969 - acc: 0.8791 - val_loss: 0.3406 - val_acc: 0.8637\n",
      "Epoch 10/500\n",
      "57/57 [==============================] - 5s 89ms/step - loss: 0.2890 - acc: 0.8816 - val_loss: 0.3187 - val_acc: 0.8768\n",
      "Epoch 11/500\n",
      "57/57 [==============================] - 5s 89ms/step - loss: 0.2774 - acc: 0.8859 - val_loss: 0.3088 - val_acc: 0.8786\n",
      "Epoch 12/500\n",
      "57/57 [==============================] - 5s 90ms/step - loss: 0.2657 - acc: 0.8883 - val_loss: 0.3081 - val_acc: 0.8707\n",
      "Epoch 13/500\n",
      "57/57 [==============================] - 5s 89ms/step - loss: 0.2552 - acc: 0.8955 - val_loss: 0.3063 - val_acc: 0.8751\n",
      "Epoch 14/500\n",
      "57/57 [==============================] - 6s 102ms/step - loss: 0.2569 - acc: 0.8951 - val_loss: 0.3048 - val_acc: 0.8711\n",
      "Epoch 15/500\n",
      "57/57 [==============================] - 6s 107ms/step - loss: 0.2381 - acc: 0.8981 - val_loss: 0.2996 - val_acc: 0.8756\n",
      "Epoch 16/500\n",
      "57/57 [==============================] - 5s 95ms/step - loss: 0.2281 - acc: 0.9055 - val_loss: 0.3058 - val_acc: 0.8716\n",
      "Epoch 17/500\n",
      "57/57 [==============================] - 5s 96ms/step - loss: 0.2266 - acc: 0.9046 - val_loss: 0.2903 - val_acc: 0.8796\n",
      "Epoch 18/500\n",
      "57/57 [==============================] - 5s 95ms/step - loss: 0.2126 - acc: 0.9130 - val_loss: 0.2980 - val_acc: 0.8798\n",
      "Epoch 19/500\n",
      "57/57 [==============================] - 5s 94ms/step - loss: 0.1996 - acc: 0.9165 - val_loss: 0.2922 - val_acc: 0.8824\n",
      "Epoch 00019: early stopping\n"
     ]
    }
   ],
   "source": [
    "H = classifier.fit_generator(aug.flow(trainX, trainY, batch_size=BS),\n",
    "    validation_data=(testX, testY), steps_per_epoch=len(trainX) // BS,\n",
    "    epochs=EPOCHS, verbose=1, callbacks=[es]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.save('model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = cv2.imread('test2.jpeg')\n",
    "orig = image.copy()\n",
    "image = cv2.resize(image, (w,h))#resize image maintaining aspect ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#image = cv2.resize(image, (28, 28))\n",
    "image = image.astype(\"float\") / 255.0\n",
    "image = img_to_array(image)\n",
    "image = np.expand_dims(image, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8.0661215e-03 9.6881300e-01 1.3018930e-03 1.8389512e-02 1.4602761e-03\n",
      " 1.9652881e-03 3.9248334e-06]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Disgusted'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat = ['Angry','Disgusted','Afraid','Sad','Happy','Neutral','Suprised']\n",
    "arr = classifier.predict(image)[0]\n",
    "print(arr)\n",
    "res = np.amax(arr)\n",
    "cat[np.where(arr == res)[0][0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] compiling model...\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_68 (Conv2D)           (None, 43, 65, 32)        896       \n",
      "_________________________________________________________________\n",
      "activation_51 (Activation)   (None, 43, 65, 32)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_48 (Batc (None, 43, 65, 32)        128       \n",
      "_________________________________________________________________\n",
      "conv2d_69 (Conv2D)           (None, 43, 65, 32)        9248      \n",
      "_________________________________________________________________\n",
      "activation_52 (Activation)   (None, 43, 65, 32)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_49 (Batc (None, 43, 65, 32)        128       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_43 (MaxPooling (None, 21, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_22 (Dropout)         (None, 21, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_70 (Conv2D)           (None, 21, 32, 64)        18496     \n",
      "_________________________________________________________________\n",
      "activation_53 (Activation)   (None, 21, 32, 64)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_50 (Batc (None, 21, 32, 64)        256       \n",
      "_________________________________________________________________\n",
      "conv2d_71 (Conv2D)           (None, 21, 32, 64)        36928     \n",
      "_________________________________________________________________\n",
      "activation_54 (Activation)   (None, 21, 32, 64)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_51 (Batc (None, 21, 32, 64)        256       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_44 (MaxPooling (None, 10, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_23 (Dropout)         (None, 10, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_72 (Conv2D)           (None, 10, 16, 128)       73856     \n",
      "_________________________________________________________________\n",
      "activation_55 (Activation)   (None, 10, 16, 128)       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_52 (Batc (None, 10, 16, 128)       512       \n",
      "_________________________________________________________________\n",
      "conv2d_73 (Conv2D)           (None, 10, 16, 128)       147584    \n",
      "_________________________________________________________________\n",
      "activation_56 (Activation)   (None, 10, 16, 128)       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_53 (Batc (None, 10, 16, 128)       512       \n",
      "_________________________________________________________________\n",
      "conv2d_74 (Conv2D)           (None, 10, 16, 128)       147584    \n",
      "_________________________________________________________________\n",
      "activation_57 (Activation)   (None, 10, 16, 128)       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_54 (Batc (None, 10, 16, 128)       512       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_45 (MaxPooling (None, 5, 8, 128)         0         \n",
      "_________________________________________________________________\n",
      "dropout_24 (Dropout)         (None, 5, 8, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_75 (Conv2D)           (None, 5, 8, 256)         295168    \n",
      "_________________________________________________________________\n",
      "activation_58 (Activation)   (None, 5, 8, 256)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_55 (Batc (None, 5, 8, 256)         1024      \n",
      "_________________________________________________________________\n",
      "conv2d_76 (Conv2D)           (None, 5, 8, 256)         590080    \n",
      "_________________________________________________________________\n",
      "activation_59 (Activation)   (None, 5, 8, 256)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_56 (Batc (None, 5, 8, 256)         1024      \n",
      "_________________________________________________________________\n",
      "conv2d_77 (Conv2D)           (None, 5, 8, 256)         590080    \n",
      "_________________________________________________________________\n",
      "activation_60 (Activation)   (None, 5, 8, 256)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_57 (Batc (None, 5, 8, 256)         1024      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_46 (MaxPooling (None, 2, 4, 256)         0         \n",
      "_________________________________________________________________\n",
      "dropout_25 (Dropout)         (None, 2, 4, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_78 (Conv2D)           (None, 2, 4, 256)         590080    \n",
      "_________________________________________________________________\n",
      "activation_61 (Activation)   (None, 2, 4, 256)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_58 (Batc (None, 2, 4, 256)         1024      \n",
      "_________________________________________________________________\n",
      "conv2d_79 (Conv2D)           (None, 2, 4, 256)         590080    \n",
      "_________________________________________________________________\n",
      "activation_62 (Activation)   (None, 2, 4, 256)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_59 (Batc (None, 2, 4, 256)         1024      \n",
      "_________________________________________________________________\n",
      "conv2d_80 (Conv2D)           (None, 2, 4, 256)         590080    \n",
      "_________________________________________________________________\n",
      "activation_63 (Activation)   (None, 2, 4, 256)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_60 (Batc (None, 2, 4, 256)         1024      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_47 (MaxPooling (None, 1, 2, 256)         0         \n",
      "_________________________________________________________________\n",
      "dropout_26 (Dropout)         (None, 1, 2, 256)         0         \n",
      "_________________________________________________________________\n",
      "flatten_17 (Flatten)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_36 (Dense)             (None, 2048)              1050624   \n",
      "_________________________________________________________________\n",
      "activation_64 (Activation)   (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_61 (Batc (None, 2048)              8192      \n",
      "_________________________________________________________________\n",
      "dropout_27 (Dropout)         (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_37 (Dense)             (None, 2048)              4196352   \n",
      "_________________________________________________________________\n",
      "activation_65 (Activation)   (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_62 (Batc (None, 2048)              8192      \n",
      "_________________________________________________________________\n",
      "dropout_28 (Dropout)         (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_38 (Dense)             (None, 6)                 12294     \n",
      "_________________________________________________________________\n",
      "activation_66 (Activation)   (None, 6)                 0         \n",
      "=================================================================\n",
      "Total params: 8,964,262\n",
      "Trainable params: 8,951,846\n",
      "Non-trainable params: 12,416\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(\"[INFO] compiling model...\")\n",
    "model = SmallerVGGNet.build(width=w, height=h, depth=3, classes=6)\n",
    "\n",
    "sgd = optimizers.SGD(lr=0.0005, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "model.compile(loss='binary_crossentropy', optimizer= sgd, metrics=['accuracy'])\n",
    "\n",
    "\n",
    "#opt = Adam(lr=INIT_LR, decay=INIT_LR / EPOCHS)\n",
    "#model.compile(loss=\"binary_crossentropy\", optimizer=opt,\n",
    "#\tmetrics=[\"accuracy\"])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] training network...\n",
      "Epoch 1/500\n",
      "57/57 [==============================] - 94s 2s/step - loss: 0.7199 - acc: 0.7640 - val_loss: 0.6864 - val_acc: 0.7865\n",
      "Epoch 2/500\n",
      "57/57 [==============================] - 89s 2s/step - loss: 0.7077 - acc: 0.7639 - val_loss: 0.5908 - val_acc: 0.7938\n",
      "Epoch 3/500\n",
      "57/57 [==============================] - 90s 2s/step - loss: 0.6938 - acc: 0.7674 - val_loss: 0.5019 - val_acc: 0.8200\n",
      "Epoch 4/500\n",
      "57/57 [==============================] - 90s 2s/step - loss: 0.7090 - acc: 0.7657 - val_loss: 0.4860 - val_acc: 0.8271\n",
      "Epoch 5/500\n",
      "57/57 [==============================] - 90s 2s/step - loss: 0.6729 - acc: 0.7705 - val_loss: 0.4862 - val_acc: 0.8284\n",
      "Epoch 6/500\n",
      "57/57 [==============================] - 90s 2s/step - loss: 0.6742 - acc: 0.7681 - val_loss: 0.4744 - val_acc: 0.8301\n",
      "Epoch 7/500\n",
      "57/57 [==============================] - 90s 2s/step - loss: 0.6605 - acc: 0.7710 - val_loss: 0.4768 - val_acc: 0.8312\n",
      "Epoch 8/500\n",
      "57/57 [==============================] - 90s 2s/step - loss: 0.6603 - acc: 0.7705 - val_loss: 0.4666 - val_acc: 0.8328\n",
      "Epoch 9/500\n",
      "57/57 [==============================] - 90s 2s/step - loss: 0.6495 - acc: 0.7750 - val_loss: 0.4733 - val_acc: 0.8320\n",
      "Epoch 10/500\n",
      "57/57 [==============================] - 90s 2s/step - loss: 0.6555 - acc: 0.7736 - val_loss: 0.4681 - val_acc: 0.8325\n",
      "Epoch 11/500\n",
      "57/57 [==============================] - 89s 2s/step - loss: 0.6365 - acc: 0.7755 - val_loss: 0.4658 - val_acc: 0.8328\n",
      "Epoch 12/500\n",
      "57/57 [==============================] - 89s 2s/step - loss: 0.6351 - acc: 0.7760 - val_loss: 0.4650 - val_acc: 0.8328\n",
      "Epoch 13/500\n",
      "57/57 [==============================] - 89s 2s/step - loss: 0.6218 - acc: 0.7771 - val_loss: 0.4609 - val_acc: 0.8328\n",
      "Epoch 14/500\n",
      "57/57 [==============================] - 89s 2s/step - loss: 0.6148 - acc: 0.7824 - val_loss: 0.4584 - val_acc: 0.8331\n",
      "Epoch 15/500\n",
      "57/57 [==============================] - 89s 2s/step - loss: 0.6165 - acc: 0.7806 - val_loss: 0.4756 - val_acc: 0.8320\n",
      "Epoch 16/500\n",
      "57/57 [==============================] - 89s 2s/step - loss: 0.5998 - acc: 0.7813 - val_loss: 0.4725 - val_acc: 0.8325\n",
      "Epoch 17/500\n",
      "57/57 [==============================] - 89s 2s/step - loss: 0.6123 - acc: 0.7817 - val_loss: 0.4770 - val_acc: 0.8320\n",
      "Epoch 18/500\n",
      "57/57 [==============================] - 89s 2s/step - loss: 0.5904 - acc: 0.7855 - val_loss: 0.4662 - val_acc: 0.8331\n",
      "Epoch 19/500\n",
      "57/57 [==============================] - 89s 2s/step - loss: 0.6091 - acc: 0.7811 - val_loss: 0.4706 - val_acc: 0.8328\n",
      "Epoch 20/500\n",
      "57/57 [==============================] - 89s 2s/step - loss: 0.5783 - acc: 0.7907 - val_loss: 0.4627 - val_acc: 0.8325\n",
      "Epoch 21/500\n",
      "57/57 [==============================] - 91s 2s/step - loss: 0.5948 - acc: 0.7869 - val_loss: 0.4628 - val_acc: 0.8333\n",
      "Epoch 22/500\n",
      "57/57 [==============================] - 89s 2s/step - loss: 0.5768 - acc: 0.7882 - val_loss: 0.4708 - val_acc: 0.8333\n",
      "Epoch 23/500\n",
      "57/57 [==============================] - 89s 2s/step - loss: 0.5826 - acc: 0.7890 - val_loss: 0.4803 - val_acc: 0.8328\n",
      "Epoch 24/500\n",
      "57/57 [==============================] - 89s 2s/step - loss: 0.5811 - acc: 0.7905 - val_loss: 0.4672 - val_acc: 0.8325\n",
      "Epoch 25/500\n",
      "57/57 [==============================] - 89s 2s/step - loss: 0.5822 - acc: 0.7911 - val_loss: 0.4655 - val_acc: 0.8328\n",
      "Epoch 26/500\n",
      "57/57 [==============================] - 88s 2s/step - loss: 0.5703 - acc: 0.7917 - val_loss: 0.4626 - val_acc: 0.8333\n",
      "Epoch 27/500\n",
      "57/57 [==============================] - 89s 2s/step - loss: 0.5574 - acc: 0.7965 - val_loss: 0.4592 - val_acc: 0.8328\n",
      "Epoch 28/500\n",
      "57/57 [==============================] - 89s 2s/step - loss: 0.5577 - acc: 0.7946 - val_loss: 0.4550 - val_acc: 0.8328\n",
      "Epoch 29/500\n",
      "57/57 [==============================] - 89s 2s/step - loss: 0.5497 - acc: 0.8020 - val_loss: 0.4582 - val_acc: 0.8328\n",
      "Epoch 30/500\n",
      "57/57 [==============================] - 89s 2s/step - loss: 0.5533 - acc: 0.7950 - val_loss: 0.4574 - val_acc: 0.8328\n",
      "Epoch 31/500\n",
      "57/57 [==============================] - 89s 2s/step - loss: 0.5581 - acc: 0.7945 - val_loss: 0.4565 - val_acc: 0.8328\n",
      "Epoch 32/500\n",
      "57/57 [==============================] - 89s 2s/step - loss: 0.5441 - acc: 0.8009 - val_loss: 0.4604 - val_acc: 0.8328\n",
      "Epoch 33/500\n",
      "57/57 [==============================] - 89s 2s/step - loss: 0.5378 - acc: 0.8003 - val_loss: 0.4579 - val_acc: 0.8331\n",
      "Epoch 34/500\n",
      "57/57 [==============================] - 89s 2s/step - loss: 0.5383 - acc: 0.8013 - val_loss: 0.4575 - val_acc: 0.8328\n",
      "Epoch 35/500\n",
      "57/57 [==============================] - 88s 2s/step - loss: 0.5473 - acc: 0.7989 - val_loss: 0.4521 - val_acc: 0.8331\n",
      "Epoch 36/500\n",
      "57/57 [==============================] - 88s 2s/step - loss: 0.5342 - acc: 0.8015 - val_loss: 0.4548 - val_acc: 0.8328\n",
      "Epoch 37/500\n",
      "57/57 [==============================] - 88s 2s/step - loss: 0.5484 - acc: 0.8033 - val_loss: 0.4546 - val_acc: 0.8328\n",
      "Epoch 38/500\n",
      "57/57 [==============================] - 88s 2s/step - loss: 0.5410 - acc: 0.8026 - val_loss: 0.4583 - val_acc: 0.8328\n",
      "Epoch 39/500\n",
      "57/57 [==============================] - 88s 2s/step - loss: 0.5363 - acc: 0.7996 - val_loss: 0.4592 - val_acc: 0.8325\n",
      "Epoch 40/500\n",
      "57/57 [==============================] - 88s 2s/step - loss: 0.5297 - acc: 0.8039 - val_loss: 0.4588 - val_acc: 0.8328\n",
      "Epoch 41/500\n",
      "57/57 [==============================] - 88s 2s/step - loss: 0.5194 - acc: 0.8075 - val_loss: 0.4528 - val_acc: 0.8328\n",
      "Epoch 42/500\n",
      "57/57 [==============================] - 88s 2s/step - loss: 0.5250 - acc: 0.8064 - val_loss: 0.4558 - val_acc: 0.8325\n",
      "Epoch 43/500\n",
      "57/57 [==============================] - 88s 2s/step - loss: 0.5211 - acc: 0.8045 - val_loss: 0.4546 - val_acc: 0.8325\n",
      "Epoch 44/500\n",
      "57/57 [==============================] - 88s 2s/step - loss: 0.5241 - acc: 0.8091 - val_loss: 0.4566 - val_acc: 0.8328\n",
      "Epoch 45/500\n",
      "57/57 [==============================] - 90s 2s/step - loss: 0.5309 - acc: 0.8054 - val_loss: 0.4548 - val_acc: 0.8333\n",
      "Epoch 46/500\n",
      "57/57 [==============================] - 89s 2s/step - loss: 0.5166 - acc: 0.8080 - val_loss: 0.4553 - val_acc: 0.8328\n",
      "Epoch 47/500\n",
      "57/57 [==============================] - 89s 2s/step - loss: 0.5173 - acc: 0.8110 - val_loss: 0.4548 - val_acc: 0.8328\n",
      "Epoch 48/500\n",
      "57/57 [==============================] - 89s 2s/step - loss: 0.5214 - acc: 0.8076 - val_loss: 0.4512 - val_acc: 0.8328\n",
      "Epoch 49/500\n",
      "57/57 [==============================] - 89s 2s/step - loss: 0.5079 - acc: 0.8132 - val_loss: 0.4519 - val_acc: 0.8331\n",
      "Epoch 50/500\n",
      "57/57 [==============================] - 89s 2s/step - loss: 0.5152 - acc: 0.8078 - val_loss: 0.4534 - val_acc: 0.8333\n",
      "Epoch 51/500\n",
      "57/57 [==============================] - 89s 2s/step - loss: 0.5155 - acc: 0.8140 - val_loss: 0.4578 - val_acc: 0.8331\n",
      "Epoch 52/500\n",
      "57/57 [==============================] - 89s 2s/step - loss: 0.5101 - acc: 0.8081 - val_loss: 0.4537 - val_acc: 0.8331\n",
      "Epoch 53/500\n",
      "57/57 [==============================] - 89s 2s/step - loss: 0.5046 - acc: 0.8153 - val_loss: 0.4497 - val_acc: 0.8328\n",
      "Epoch 54/500\n",
      "57/57 [==============================] - 89s 2s/step - loss: 0.5075 - acc: 0.8133 - val_loss: 0.4494 - val_acc: 0.8325\n",
      "Epoch 55/500\n",
      "57/57 [==============================] - 89s 2s/step - loss: 0.5037 - acc: 0.8135 - val_loss: 0.4468 - val_acc: 0.8331\n",
      "Epoch 56/500\n",
      "57/57 [==============================] - 90s 2s/step - loss: 0.5007 - acc: 0.8180 - val_loss: 0.4498 - val_acc: 0.8325\n",
      "Epoch 57/500\n",
      "57/57 [==============================] - 89s 2s/step - loss: 0.4916 - acc: 0.8160 - val_loss: 0.4498 - val_acc: 0.8325\n",
      "Epoch 58/500\n",
      "57/57 [==============================] - 89s 2s/step - loss: 0.4975 - acc: 0.8151 - val_loss: 0.4476 - val_acc: 0.8328\n",
      "Epoch 59/500\n",
      "57/57 [==============================] - 90s 2s/step - loss: 0.4980 - acc: 0.8159 - val_loss: 0.4515 - val_acc: 0.8325\n",
      "Epoch 60/500\n",
      "57/57 [==============================] - 89s 2s/step - loss: 0.4905 - acc: 0.8187 - val_loss: 0.4495 - val_acc: 0.8325\n",
      "Epoch 61/500\n",
      "57/57 [==============================] - 89s 2s/step - loss: 0.4877 - acc: 0.8185 - val_loss: 0.4480 - val_acc: 0.8325\n",
      "Epoch 62/500\n",
      "57/57 [==============================] - 90s 2s/step - loss: 0.4874 - acc: 0.8182 - val_loss: 0.4493 - val_acc: 0.8325\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 63/500\n",
      "57/57 [==============================] - 89s 2s/step - loss: 0.4871 - acc: 0.8194 - val_loss: 0.4492 - val_acc: 0.8328\n",
      "Epoch 64/500\n",
      "57/57 [==============================] - 89s 2s/step - loss: 0.4949 - acc: 0.8174 - val_loss: 0.4476 - val_acc: 0.8328\n",
      "Epoch 65/500\n",
      "57/57 [==============================] - 89s 2s/step - loss: 0.4856 - acc: 0.8207 - val_loss: 0.4481 - val_acc: 0.8328\n",
      "Epoch 66/500\n",
      "57/57 [==============================] - 89s 2s/step - loss: 0.4832 - acc: 0.8192 - val_loss: 0.4461 - val_acc: 0.8328\n",
      "Epoch 67/500\n",
      "57/57 [==============================] - 89s 2s/step - loss: 0.4900 - acc: 0.8212 - val_loss: 0.4453 - val_acc: 0.8328\n",
      "Epoch 68/500\n",
      "57/57 [==============================] - 89s 2s/step - loss: 0.4781 - acc: 0.8223 - val_loss: 0.4458 - val_acc: 0.8325\n",
      "Epoch 69/500\n",
      "57/57 [==============================] - 89s 2s/step - loss: 0.4748 - acc: 0.8258 - val_loss: 0.4455 - val_acc: 0.8328\n",
      "Epoch 70/500\n",
      "57/57 [==============================] - 89s 2s/step - loss: 0.4886 - acc: 0.8207 - val_loss: 0.4460 - val_acc: 0.8328\n",
      "Epoch 71/500\n",
      "57/57 [==============================] - 89s 2s/step - loss: 0.4760 - acc: 0.8231 - val_loss: 0.4455 - val_acc: 0.8325\n",
      "Epoch 72/500\n",
      "57/57 [==============================] - 90s 2s/step - loss: 0.4824 - acc: 0.8213 - val_loss: 0.4463 - val_acc: 0.8328\n",
      "Epoch 73/500\n",
      "57/57 [==============================] - 89s 2s/step - loss: 0.4772 - acc: 0.8237 - val_loss: 0.4462 - val_acc: 0.8328\n",
      "Epoch 74/500\n",
      "57/57 [==============================] - 89s 2s/step - loss: 0.4775 - acc: 0.8218 - val_loss: 0.4444 - val_acc: 0.8328\n",
      "Epoch 75/500\n",
      "57/57 [==============================] - 90s 2s/step - loss: 0.4736 - acc: 0.8254 - val_loss: 0.4444 - val_acc: 0.8328\n",
      "Epoch 76/500\n",
      "57/57 [==============================] - 91s 2s/step - loss: 0.4754 - acc: 0.8236 - val_loss: 0.4440 - val_acc: 0.8328\n",
      "Epoch 77/500\n",
      "57/57 [==============================] - 92s 2s/step - loss: 0.4685 - acc: 0.8276 - val_loss: 0.4457 - val_acc: 0.8328\n",
      "Epoch 78/500\n",
      "57/57 [==============================] - 88s 2s/step - loss: 0.4724 - acc: 0.8258 - val_loss: 0.4448 - val_acc: 0.8328\n",
      "Epoch 79/500\n",
      "57/57 [==============================] - 88s 2s/step - loss: 0.4773 - acc: 0.8215 - val_loss: 0.4436 - val_acc: 0.8328\n",
      "Epoch 80/500\n",
      "57/57 [==============================] - 91s 2s/step - loss: 0.4754 - acc: 0.8244 - val_loss: 0.4446 - val_acc: 0.8331\n",
      "Epoch 81/500\n",
      "57/57 [==============================] - 103s 2s/step - loss: 0.4729 - acc: 0.8249 - val_loss: 0.4441 - val_acc: 0.8333\n",
      "Epoch 82/500\n",
      "57/57 [==============================] - 88s 2s/step - loss: 0.4704 - acc: 0.8255 - val_loss: 0.4447 - val_acc: 0.8328\n",
      "Epoch 83/500\n",
      "57/57 [==============================] - 88s 2s/step - loss: 0.4716 - acc: 0.8256 - val_loss: 0.4451 - val_acc: 0.8331\n",
      "Epoch 84/500\n",
      "57/57 [==============================] - 88s 2s/step - loss: 0.4676 - acc: 0.8280 - val_loss: 0.4439 - val_acc: 0.8328\n",
      "Epoch 85/500\n",
      "57/57 [==============================] - 88s 2s/step - loss: 0.4626 - acc: 0.8261 - val_loss: 0.4448 - val_acc: 0.8331\n",
      "Epoch 86/500\n",
      "57/57 [==============================] - 88s 2s/step - loss: 0.4670 - acc: 0.8262 - val_loss: 0.4457 - val_acc: 0.8333\n",
      "Epoch 87/500\n",
      "57/57 [==============================] - 88s 2s/step - loss: 0.4743 - acc: 0.8250 - val_loss: 0.4450 - val_acc: 0.8331\n",
      "Epoch 88/500\n",
      "57/57 [==============================] - 88s 2s/step - loss: 0.4680 - acc: 0.8267 - val_loss: 0.4458 - val_acc: 0.8328\n",
      "Epoch 89/500\n",
      "56/57 [============================>.] - ETA: 1s - loss: 0.4650 - acc: 0.8281"
     ]
    }
   ],
   "source": [
    "print(\"[INFO] training network...\")\n",
    "# simple early stopping\n",
    "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=30)\n",
    "\n",
    "H = model.fit_generator(aug.flow(trainX, trainY, batch_size=BS),\n",
    "\tvalidation_data=(testX, testY), steps_per_epoch=len(trainX) // BS,\n",
    "\tepochs=EPOCHS, verbose=1, callbacks=[es])\n",
    "\n",
    "# save the model to disk\n",
    "print(\"[INFO] serializing network...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the model to disk\n",
    "print(\"[INFO] serializing network...\")\n",
    "model.save('VGGModel.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DirectoryIterator' object has no attribute 'ndim'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-50258f4960d7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_set\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#Number of test sets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mclassifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_set\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m>\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0mpred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps)\u001b[0m\n\u001b[1;32m   1147\u001b[0m                              'argument.')\n\u001b[1;32m   1148\u001b[0m         \u001b[0;31m# Validate user data.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1149\u001b[0;31m         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_standardize_user_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1150\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstateful\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, check_array_lengths, batch_size)\u001b[0m\n\u001b[1;32m    749\u001b[0m             \u001b[0mfeed_input_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    750\u001b[0m             \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# Don't enforce the batch size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 751\u001b[0;31m             exception_prefix='input')\n\u001b[0m\u001b[1;32m    752\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    753\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/keras/engine/training_utils.py\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[0;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[1;32m     90\u001b[0m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'DataFrame'\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mstandardize_single_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnames\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/keras/engine/training_utils.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     90\u001b[0m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'DataFrame'\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mstandardize_single_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnames\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/keras/engine/training_utils.py\u001b[0m in \u001b[0;36mstandardize_single_array\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m     25\u001b[0m                 'Got tensor with shape: %s' % str(shape))\n\u001b[1;32m     26\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m     \u001b[0;32melif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'DirectoryIterator' object has no attribute 'ndim'"
     ]
    }
   ],
   "source": [
    "EPOCHS = len(H.history['loss'])\n",
    "p = len(test_set) #Number of test sets\n",
    "pred = []\n",
    "for a in classifier.predict(test_set):\n",
    "    if a[1]>a[0]:\n",
    "        pred.append(1)\n",
    "    else:\n",
    "        pred.append(0)\n",
    "score  = model.evaluate(testX,testY)[1]\n",
    "z = 1.96 * sqrt( (score * (1 - score)) / p)\n",
    "print('Accuracy:',round(score,2),'+/-',round(z,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
